# Ollama Configuration for AI Email Generation
# See docs/ai/README.md for complete setup instructions

# Ollama Server URL
# Local development: http://localhost:11434
# Remote server: http://YOUR_SERVER_IP:11434
# With domain: https://ollama.yourdomain.com
OLLAMA_BASE_URL=http://localhost:11434

# Ollama Model
# Recommended: llama3.1:8b (best balance of speed and quality)
# Fast/Low RAM: llama3.1:8b-instruct-q4_0
# Best quality: llama3.1:70b (requires 64GB RAM)
OLLAMA_MODEL=llama3.1:8b

# Quick Start:
# 1. Install Ollama: curl -fsSL https://ollama.com/install.sh | sh
# 2. Pull model: ollama pull llama3.1:8b
# 3. Start server: ollama serve
# 4. Test: curl http://localhost:11434/api/tags
#
# Remote Setup:
# See docs/ai/ollama_remote_setup.md for complete instructions
